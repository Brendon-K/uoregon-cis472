{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaf Classification CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#%tensorflow_version 2.x\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys, os, shutil, glob, random, csv, time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IO functions\n",
    "\n",
    "def load_image(file_path):\n",
    "    return cv2.imread(file_path)\n",
    "\n",
    "def create_directory(dirname):\n",
    "    try:\n",
    "        os.mkdir(dirname)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "def extract_names(label_file):\n",
    "    names = list()\n",
    "    with open('label_legend.csv', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        legend = dict(reader)\n",
    "    for img in label_file:\n",
    "        names.append(legend[str(img)])\n",
    "    return names\n",
    "\n",
    "def process_data(source_path, dest_path, desired_size, transform=False, edges=False):\n",
    "    create_directory(dest_path)\n",
    "    names = []\n",
    "    legend = dict()\n",
    "    j=0\n",
    "    species_folders = os.listdir(source_path)\n",
    "    for i, folder in enumerate(species_folders):\n",
    "        if folder[0] == '.':\n",
    "            continue\n",
    "        id = str(i).rjust(2, '0')\n",
    "        legend[folder] = id\n",
    "        folder_path = os.listdir(os.path.join(source_path, folder))\n",
    "        num_folders = len(folder_path)\n",
    "        clear_output(wait=True)\n",
    "        print(\"Folder:\", i, \"/100\", flush=True)\n",
    "        for jpgfile in folder_path:\n",
    "            #resize\n",
    "            img = load_image(os.path.join(source_path, folder, jpgfile))\n",
    "            old_size = img.shape[:2]\n",
    "            ratio = float(desired_size)/max(old_size)\n",
    "            new_size = tuple([int(x*ratio) for x in old_size])\n",
    "            img = cv2.resize(img, (new_size[1], new_size[0]))\n",
    "            delta_w = desired_size - new_size[1]\n",
    "            delta_h = desired_size - new_size[0]\n",
    "            top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "            left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "            color = [0, 0, 0]\n",
    "            new_im = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
    "                value=color)\n",
    "            new_im = cv2.cvtColor(new_im, cv2.COLOR_BGR2GRAY)\n",
    "            (thresh, new_im) = cv2.threshold(new_im, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "            #rename\n",
    "            new_name = id + str(j)\n",
    "            j += 1\n",
    "            fname = os.path.join(dest_path, new_name)\n",
    "            if edges:\n",
    "                new_im = cv2.Canny(img, 100, 200)\n",
    "            if transform:\n",
    "                # 2x mirror\n",
    "                img_flip_vert = np.flip(new_im, axis=0)\n",
    "                filename = os.path.join(fname + '_vert.jpg')\n",
    "                cv2.imwrite(filename, img_flip_vert)\n",
    "\n",
    "                img_flip_horiz = np.flip(new_im, axis=1)\n",
    "                filename = os.path.join(fname + '_horiz.jpg')\n",
    "                cv2.imwrite(filename, img_flip_horiz)\n",
    "\n",
    "                # rotate 3 times and save\n",
    "                for i in range(1, 4):\n",
    "                    img_flip_vert = cv2.rotate(img_flip_vert, cv2.ROTATE_90_CLOCKWISE)\n",
    "                    filename = os.path.join(fname + '_' + str(i*90) + '_vert.jpg')\n",
    "                    cv2.imwrite(filename, img_flip_vert)\n",
    "\n",
    "                    img_flip_horiz = cv2.rotate(img_flip_horiz, cv2.ROTATE_90_CLOCKWISE)\n",
    "                    filename = os.path.join(fname + '_' + str(i*90) + '_horiz.jpg')\n",
    "                    cv2.imwrite(filename, img_flip_horiz)\n",
    "\n",
    "            cv2.imwrite(os.path.join(fname+'.jpg'), new_im)\n",
    "            #shutil.copy(jpgfile, os.path.join(dest_path, new_name+'.jpg'))        \n",
    "    csv_name = 'label_legend.csv'\n",
    "    with open(csv_name, 'w') as csvfile:\n",
    "        for key in legend.keys():\n",
    "            csvfile.write(\"%d,%s\\n\"%(int(legend[key]), key))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: 100 /99\r\n"
     ]
    }
   ],
   "source": [
    "#copy dataset into dest_name folder and create a 'label legend'\n",
    "\n",
    "dest_name = 'sixty_four'\n",
    "desired_size = 64\n",
    "\n",
    "#root_path = os.path.join(os.getcwd(), 'drive', 'My Drive', 'datasets')\n",
    "root_path = os.path.join(os.getcwd(), 'datasets')\n",
    "dest_path = os.path.join(root_path, dest_name)\n",
    "process_data(os.path.join(root_path, '100 leaves plant species', 'data'), dest_path, desired_size, transform=True, edges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training labels:  [34, 2, 21, 64, 46, 64, 10, 50, 43, 81]\n",
      "testing labels:  [37, 80, 18, 42, 57, 52, 32, 92, 5, 91]\n",
      "testing names: ['Pterocarya_Stenoptera', 'Quercus_Agrifolia', 'Magnolia_Heptapeta', 'Quercus_Semecarpifolia', 'Prunus_X_Shmittii', 'Quercus_Pubescens', 'Quercus_Crassifolia', 'Populus_Grandidentata', 'Quercus_Trojana', 'Betula_Austrosinensis']\n"
     ]
    }
   ],
   "source": [
    "#Split processed dataset into training and validation\n",
    "\n",
    "test_perc = .25\n",
    "random_seed = 101\n",
    "data_path = dest_path\n",
    "image_files = os.listdir(dest_path)\n",
    "data = [load_image(os.path.join(data_path, file)) for file in image_files]\n",
    "labels = [int(file[:2]) for file in image_files]\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(data, labels, test_size=test_perc, random_state=random_seed)\n",
    "test_label_name = extract_names(test_labels)\n",
    "print(\"training labels: \", train_labels[:10])\n",
    "print(\"testing labels: \", test_labels[:10])\n",
    "print(\"testing names:\", test_label_name[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess function not being used, any other processing functions can go here \n",
    "def preprocess(img, side=32):\n",
    "    #img = cv2.resize(img, (side,side))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    (thresh, img) = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "    return img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a4676ad90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preview_index = 2\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(train_images[preview_index])\n",
    "#data already mostly processed\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(preprocess(train_images[preview_index]), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leave these loops in case we do transformation or edge functions on images..\n",
    "#for i in range(len(train_images)):\n",
    "#    train_images[i] = preprocess(train_images[i])\n",
    "\n",
    "#for i in range(len(test_images)):\n",
    "#    test_images[i] = preprocess(test_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.expand_dims(train_images, axis=-1)\n",
    "train_labels = np.array(train_labels)\n",
    "print(type(train_images[0]), type(train_labels[0]))\n",
    "print(train_labels[:15])\n",
    "print(train_images.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONVOLUTIONAL NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers = [\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu, input_shape=train_images.shape[1:]),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    #tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu),\n",
    "    #tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    #tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu),\n",
    "    #tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    #tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    #tf.keras.layers.Dense(units=512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(units=256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(units=100, activation=tf.nn.softmax)\n",
    "]\n",
    "\n",
    "model = tf.keras.Sequential(layers)\n",
    "model.compile(optimizer=tf.optimizers.Adam(),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=15, batch_size=50)\n",
    "model.save_weights(\"model.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = tf.keras.Sequential(layers)\n",
    "eval_model.load_weights(\"model.tf\")\n",
    "eval_predictions = eval_model.predict(np.expand_dims(test_images, axis=-1))\n",
    "cols = 4\n",
    "rows = np.ceil(len(test_images)/cols)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(cols * 4, rows * 4)\n",
    "predicted_labels = np.argmax(eval_predictions, axis=1)\n",
    "predicted_names = extract_names(predicted_labels)\n",
    "predicted_correct = [1 if predicted_labels[i] ==  test_labels[i] else 0 for i in range(len(test_labels))  ]\n",
    "accuracy = np.sum(predicted_correct) / len(test_labels)\n",
    "print(\"Test Accuracy = \", accuracy)\n",
    "for i in range(15):\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.imshow(test_images[i], cmap=\"gray\")\n",
    "    title = predicted_names[i][10:] + \" / \" + test_label_name[i][10:]\n",
    "    plt.title(title)\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
