{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaf Classification CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#%tensorflow_version 2.x\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys, os, shutil, glob, random, csv, time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data IO / Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IO functions\n",
    "\n",
    "def load_image(file_path):\n",
    "    return cv2.imread(file_path)\n",
    "\n",
    "def create_directory(dirname):\n",
    "    try:\n",
    "        os.mkdir(dirname)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "def extract_names(label_file):\n",
    "    names = list()\n",
    "    with open('label_legend.csv', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        legend = dict(reader)\n",
    "    for img in label_file:\n",
    "        names.append(legend[str(img)])\n",
    "    return names\n",
    "\n",
    "def process_data(source_path, dest_path, desired_size, transform=False, edges=False):\n",
    "    create_directory(dest_path)\n",
    "    names = []\n",
    "    legend = dict()\n",
    "    j=0\n",
    "    species_folders = os.listdir(source_path)\n",
    "    for i, folder in enumerate(species_folders):\n",
    "        if folder[0] == '.':\n",
    "            continue\n",
    "        id = str(i).rjust(2, '0')\n",
    "        legend[folder] = id\n",
    "        folder_path = os.listdir(os.path.join(source_path, folder))\n",
    "        num_folders = len(folder_path)\n",
    "        clear_output(wait=True)\n",
    "        print(\"Folder:\", i, \"/100\", flush=True)\n",
    "        for jpgfile in folder_path:\n",
    "            #resize\n",
    "            img = load_image(os.path.join(source_path, folder, jpgfile))\n",
    "            old_size = img.shape[:2]\n",
    "            ratio = float(desired_size)/max(old_size)\n",
    "            new_size = tuple([int(x*ratio) for x in old_size])\n",
    "            img = cv2.resize(img, (new_size[1], new_size[0]))\n",
    "            delta_w = desired_size - new_size[1]\n",
    "            delta_h = desired_size - new_size[0]\n",
    "            top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "            left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "            color = [0, 0, 0]\n",
    "            new_im = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
    "                value=color)\n",
    "    \n",
    "            #rename\n",
    "            new_name = id + str(j)\n",
    "            j += 1\n",
    "            fname = os.path.join(dest_path, new_name)\n",
    "            if edges:\n",
    "                new_im = cv2.Canny(new_im, 100, 200)\n",
    "            if transform:\n",
    "                # 2x mirror\n",
    "                img_flip_vert = np.flip(new_im, axis=0)\n",
    "                filename = os.path.join(fname + '_vert.jpg')\n",
    "                cv2.imwrite(filename, img_flip_vert)\n",
    "\n",
    "                img_flip_horiz = np.flip(new_im, axis=1)\n",
    "                filename = os.path.join(fname + '_horiz.jpg')\n",
    "                cv2.imwrite(filename, img_flip_horiz)\n",
    "\n",
    "                # rotate 3 times and save\n",
    "                for i in range(1, 4):\n",
    "                    img_flip_vert = cv2.rotate(img_flip_vert, cv2.ROTATE_90_CLOCKWISE)\n",
    "                    filename = os.path.join(fname + '_' + str(i*90) + '_vert.jpg')\n",
    "                    cv2.imwrite(filename, img_flip_vert)\n",
    "\n",
    "                    img_flip_horiz = cv2.rotate(img_flip_horiz, cv2.ROTATE_90_CLOCKWISE)\n",
    "                    filename = os.path.join(fname + '_' + str(i*90) + '_horiz.jpg')\n",
    "                    cv2.imwrite(filename, img_flip_horiz)\n",
    "            cv2.imwrite(os.path.join(fname+'.jpg'), new_im)\n",
    "    csv_name = 'label_legend.csv'\n",
    "    with open(csv_name, 'w') as csvfile:\n",
    "        for key in legend.keys():\n",
    "            csvfile.write(\"%d,%s\\n\"%(int(legend[key]), key))\n",
    "            \n",
    "def blackandwhite(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    (thresh, img) = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "    return img / 255.0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy dataset into dest_name folder and create a 'label legend'\n",
    "\n",
    "def masterSet(dest_name='sixty-four', desired_size=64, trans=False, edge=False, test_perc=.2, seed=101):\n",
    "    #root_path = os.path.join(os.getcwd(), 'drive', 'My Drive', 'datasets')\n",
    "    root_path = os.path.join(os.getcwd(), 'datasets')\n",
    "    dest_path = os.path.join(root_path, dest_name)\n",
    "    process_data(os.path.join(root_path, '100 leaves plant species', 'data'), dest_path, desired_size, transform=trans, edges=edge)\n",
    "    data_path = dest_path\n",
    "    image_files = os.listdir(dest_path)\n",
    "    data = [load_image(os.path.join(data_path, file)) for file in image_files]\n",
    "    data = [blackandwhite(img) for img in data]\n",
    "    labels = [int(file[:2]) for file in image_files]\n",
    "    #Split processed dataset into training and validation\n",
    "    train_images, test_images, train_labels, test_labels = train_test_split(data, labels, test_size=test_perc, random_state=random_seed)\n",
    "    train_images = np.expand_dims(train_images, axis=-1)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_labels = np.array(test_labels)\n",
    "    return train_images, test_images, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: 100 /100\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'random_seed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e1cf374e2d5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasterSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-de732e121747>\u001b[0m in \u001b[0;36mmasterSet\u001b[0;34m(dest_name, desired_size, trans, edge, test_perc, seed)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#Split processed dataset into training and validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_perc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_seed' is not defined"
     ]
    }
   ],
   "source": [
    "train_images, test_images, train_labels, test_labels = masterSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_images[0]), type(train_labels[0]))\n",
    "print(train_labels[:15])\n",
    "print(train_images.shape, train_labels.shape)\n",
    "print(train_images[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONVOLUTIONAL NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "batch = 50\n",
    "\n",
    "layers = [\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu, input_shape=train_images.shape[1:]),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    #tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu),\n",
    "    #tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    #tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu),\n",
    "    #tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    #tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    #tf.keras.layers.Dense(units=512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(units=256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(units=100, activation=tf.nn.softmax)\n",
    "]\n",
    "\n",
    "model = tf.keras.Sequential(layers)\n",
    "model.compile(optimizer=tf.optimizers.Adam(),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "history = model.fit(train_images, train_labels, epochs=epoch, batch_size=batch)\n",
    "print(history.history)\n",
    "model.save_weights(\"model.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_name = \"CNNhist_\" + str(desired_size) + ('_trans_' if trans == True else '_') + ('edge_' if edge == True else '') + str(epoch) + '_' + str(batch)\n",
    "create_directory('hist_stats')\n",
    "csv_file = os.path.join('hist_stats', hist_name + '.csv')\n",
    "hist = history.history\n",
    "try:\n",
    "    with open(csv_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(hist.keys())\n",
    "        writer.writerows(zip(*hist.values()))       \n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = tf.keras.Sequential(layers)\n",
    "eval_model.load_weights(\"model.tf\")\n",
    "eval_predictions = eval_model.predict(np.expand_dims(test_images, axis=-1))\n",
    "cols = 4\n",
    "rows = np.ceil(len(test_images)/cols)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(cols * 4, rows * 4)\n",
    "predicted_labels = np.argmax(eval_predictions, axis=1)\n",
    "predicted_names = extract_names(predicted_labels)\n",
    "predicted_correct = [1 if predicted_labels[i] ==  test_labels[i] else 0 for i in range(len(test_labels))  ]\n",
    "accuracy = np.sum(predicted_correct) / len(test_labels)\n",
    "print(\"Test Accuracy = \", accuracy)\n",
    "for i in range(15):\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.imshow(test_images[i], cmap=\"gray\")\n",
    "    title = predicted_names[i][10:] + \" / \" + test_label_name[i][10:]\n",
    "    plt.title(title)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance between instances x1 and x2\n",
    "def dist(x1, x2):\n",
    "    distance = x1 - x2\n",
    "    return np.linalg.norm(distance)\n",
    "\n",
    "# Predict label for instance x, using k nearest neighbors in training data\n",
    "def classify_knn(train_x, train_y, k, x):\n",
    "    # keep a list of all the distances with the values\n",
    "    distances = []\n",
    "    for i, data in enumerate(train_x):\n",
    "        # caluclate distance between x and data\n",
    "        distance = dist(x, data)\n",
    "        # add distance and label to list\n",
    "        distances.append((distance, train_y[i]))\n",
    "\n",
    "    # sort list of distances\n",
    "    distances.sort()\n",
    "\n",
    "    # tally up the results of the first k items in the sorted list\n",
    "    results = {}\n",
    "    best = (None, 0)\n",
    "    for i in range(k):\n",
    "        distance, label = distances[i]\n",
    "        # increment label by 1 if the label exists, or set to 1 if it doesn't\n",
    "        results[label] = results.get(label, 0) + 1\n",
    "        # keep track of the label with the most \"votes\"\n",
    "        if (results[label] > best[1]):\n",
    "            best = (label, results[label])\n",
    "\n",
    "    return best[0]\n",
    "\n",
    "# Run classifier and compute accuracy\n",
    "def runTest(test_x, test_y, train_x, train_y, k):\n",
    "    num_iters = test_x.shape[0]\n",
    "    correct = 0\n",
    "    i = 1\n",
    "    for (x,y) in zip(test_x, test_y):\n",
    "        clear_output(wait=True)\n",
    "        print('progress: {:.2f}% complete'.format(100* i/num_iters))\n",
    "        i += 1\n",
    "        if classify_knn(train_x, train_y, k, x) == y:\n",
    "            correct += 1\n",
    "    acc = float(correct)/len(test_x)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = [((10, 1, 'transformations', 'only edge'), 0.6738888888888889), \\\n",
    "           ((10, 1, 'transformations', 'whole image'), 0.6947222222222222), \\\n",
    "           ((10, 1, 'no transformations', 'only edge'), 0.3675), \\\n",
    "           ((10, 1, 'no transformations', 'whole image'), 0.4025), \\\n",
    "           ((10, 3, 'transformations', 'only edge'), 0.43833333333333335), \\\n",
    "           ((10, 3, 'transformations', 'whole image'), 0.4661111111111111), \\\n",
    "           ((10, 3, 'no transformations', 'only edge'), 0.39), \\\n",
    "           ((10, 3, 'no transformations', 'whole image'), 0.4075), \\\n",
    "           ((10, 5, 'transformations', 'only edge'), 0.37083333333333335), \\\n",
    "           ((10, 5, 'transformations', 'whole image'), 0.4022222222222222), \\\n",
    "           ((10, 5, 'no transformations', 'only edge'), 0.3775), \\\n",
    "           ((10, 5, 'no transformations', 'whole image'), 0.3925), \\\n",
    "           ((10, 10, 'transformations', 'only edge'), 0.36194444444444446), \\\n",
    "           ((10, 10, 'transformations', 'whole image'), 0.39861111111111114), \\\n",
    "           ((10, 10, 'no transformations', 'only edge'), 0.3375), \\\n",
    "           ((10, 10, 'no transformations', 'whole image'), 0.385), \\\n",
    "           ((16, 1, 'transformations', 'only edge'), 0.7794444444444445), \\\n",
    "           ((16, 1, 'transformations', 'whole image'), 0.7991666666666667), \\\n",
    "           ((16, 1, 'no transformations', 'only edge'), 0.3525), \\\n",
    "           ((16, 1, 'no transformations', 'whole image'), 0.4325), \\\n",
    "           ((16, 3, 'transformations', 'only edge'), 0.5027777777777778), \\\n",
    "           ((16, 3, 'transformations', 'whole image'), 0.5547222222222222), \\\n",
    "           ((16, 3, 'no transformations', 'only edge'), 0.3575), \\\n",
    "           ((16, 3, 'no transformations', 'whole image'), 0.455), \\\n",
    "           ((16, 5, 'transformations', 'only edge'), 0.41555555555555557), \\\n",
    "           ((16, 5, 'transformations', 'whole image'), 0.48083333333333333), \\\n",
    "           ((16, 5, 'no transformations', 'only edge'), 0.365), \\\n",
    "           ((16, 5, 'no transformations', 'whole image'), 0.425), \\\n",
    "           ((16, 10, 'transformations', 'only edge'), 0.41), \\\n",
    "           ((16, 10, 'transformations', 'whole image'), 0.45861111111111114), \\\n",
    "           ((16, 10, 'no transformations', 'only edge'), 0.335), \\\n",
    "           ((16, 10, 'no transformations', 'whole image'), 0.4125), \\\n",
    "           ((32, 1, 'transformations', 'only edge'), 0.7877777777777778), \\\n",
    "           ((32, 1, 'transformations', 'whole image'), 0.8155555555555556), \\\n",
    "           ((32, 1, 'no transformations', 'only edge'), 0.4375), \\\n",
    "           ((32, 1, 'no transformations', 'whole image'), 0.515), \\\n",
    "           ((32, 3, 'transformations', 'only edge'), 0.5336111111111111), \\\n",
    "           ((32, 3, 'transformations', 'whole image'), 0.6011111111111112), \\\n",
    "           ((32, 3, 'no transformations', 'only edge'), 0.4225), \\\n",
    "           ((32, 3, 'no transformations', 'whole image'), 0.5225), \\\n",
    "           ((32, 5, 'transformations', 'only edge'), 0.4375), \\\n",
    "           ((32, 5, 'transformations', 'whole image'), 0.5402777777777777), \\\n",
    "           ((32, 5, 'no transformations', 'only edge'), 0.44), \\\n",
    "           ((32, 5, 'no transformations', 'whole image'), 0.5275), \\\n",
    "           ((32, 10, 'transformations', 'only edge'), 0.42583333333333334), \\\n",
    "           ((32, 10, 'transformations', 'whole image'), 0.5222222222222223), \\\n",
    "           ((32, 10, 'no transformations', 'only edge'), 0.39), \\\n",
    "           ((32, 10, 'no transformations', 'whole image'), 0.485), \\\n",
    "           ((64, 1, 'transformations', 'only edge'), 0.7766666666666666), \\\n",
    "           ((64, 1, 'transformations', 'whole image'), 0.8177777777777778), \\\n",
    "           ((64, 1, 'no transformations', 'only edge'), 0.4075), \\\n",
    "           ((64, 1, 'no transformations', 'whole image'), 0.5375), \\\n",
    "           ((64, 3, 'transformations', 'only edge'), 0.5116666666666667), \\\n",
    "           ((64, 3, 'transformations', 'whole image'), 0.6180555555555556), \\\n",
    "           ((64, 3, 'no transformations', 'only edge'), 0.395), \\\n",
    "           ((64, 3, 'no transformations', 'whole image'), 0.53), \\\n",
    "           ((64, 5, 'transformations', 'only edge'), 0.3794444444444444), \\\n",
    "           ((64, 5, 'transformations', 'whole image'), 0.5413888888888889), \\\n",
    "           ((64, 5, 'no transformations', 'only edge'), 0.375), \\\n",
    "           ((64, 5, 'no transformations', 'whole image'), 0.5025), \\\n",
    "           ((64, 10, 'transformations', 'only edge'), 0.36972222222222223), \\\n",
    "           ((64, 10, 'transformations', 'whole image'), 0.5363888888888889), \\\n",
    "           ((64, 10, 'no transformations', 'only edge'), 0.3425), \\\n",
    "           ((64, 10, 'no transformations', 'whole image'), 0.51)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = 'transformations'\n",
    "tf = 'no transformations'\n",
    "et = 'only edge'\n",
    "ef = 'whole image'\n",
    "s10_k_tf_ef = []\n",
    "s10_k_tf_et = []\n",
    "s10_k_tt_ef = []\n",
    "s10_k_tt_et = []\n",
    "s16_k_tf_ef = []\n",
    "s16_k_tf_et = []\n",
    "s16_k_tt_ef = []\n",
    "s16_k_tt_et = []\n",
    "s32_k_tf_ef = []\n",
    "s32_k_tf_et = []\n",
    "s32_k_tt_ef = []\n",
    "s32_k_tt_et = []\n",
    "s64_k_tf_ef = []\n",
    "s64_k_tf_et = []\n",
    "s64_k_tt_ef = []\n",
    "s64_k_tt_et = []\n",
    "for params, acc in results:\n",
    "    size, k, t, e = params\n",
    "    if (size == 10):\n",
    "        if (t == tt):\n",
    "            if (e == et):\n",
    "                s10_k_tt_et.append((params, acc))\n",
    "            else:\n",
    "                s10_k_tt_ef.append((params, acc))\n",
    "        else:\n",
    "            if (e == et):\n",
    "                s10_k_tf_et.append((params, acc))\n",
    "            else:\n",
    "                s10_k_tf_ef.append((params, acc))\n",
    "    if (size == 16):\n",
    "        if (t == tt):\n",
    "            if (e == et):\n",
    "                s16_k_tt_et.append((params, acc))\n",
    "            else:\n",
    "                s16_k_tt_ef.append((params, acc))\n",
    "        else:\n",
    "            if (e == et):\n",
    "                s16_k_tf_et.append((params, acc))\n",
    "            else:\n",
    "                s16_k_tf_ef.append((params, acc))\n",
    "    if (size == 32):\n",
    "        if (t == tt):\n",
    "            if (e == et):\n",
    "                s32_k_tt_et.append((params, acc))\n",
    "            else:\n",
    "                s32_k_tt_ef.append((params, acc))\n",
    "        else:\n",
    "            if (e == et):\n",
    "                s32_k_tf_et.append((params, acc))\n",
    "            else:\n",
    "                s32_k_tf_ef.append((params, acc))\n",
    "    if (size == 64):\n",
    "        if (t == tt):\n",
    "            if (e == et):\n",
    "                s64_k_tt_et.append((params, acc))\n",
    "            else:\n",
    "                s64_k_tt_ef.append((params, acc))\n",
    "        else:\n",
    "            if (e == et):\n",
    "                s64_k_tf_et.append((params, acc))\n",
    "            else:\n",
    "                s64_k_tf_ef.append((params, acc))\n",
    "\n",
    "groups = [s10_k_tf_ef, s10_k_tf_et, s10_k_tt_ef, s10_k_tt_et, \\\n",
    "          s16_k_tf_ef, s16_k_tf_et, s16_k_tt_ef, s16_k_tt_et, \\\n",
    "          s32_k_tf_ef, s32_k_tf_et, s32_k_tt_ef, s32_k_tt_et, \\\n",
    "          s64_k_tf_ef, s64_k_tf_et, s64_k_tt_ef, s64_k_tt_et]                \n",
    "styles = ['rs--', 'rs-', 'ro--', 'ro-', \\\n",
    "          'ys--', 'ys-', 'yo--', 'yo-', \\\n",
    "          'gs--', 'gs-', 'go--', 'go-', \\\n",
    "          'bs--', 'bs-', 'bo--', 'bo-']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### size = color\n",
    "10 = r  \n",
    "16 = y  \n",
    "32 = g  \n",
    "64 = b  \n",
    "\n",
    "### t = shape\n",
    "tf = s  \n",
    "tt = o\n",
    "\n",
    "### e = line\n",
    "ef = --  \n",
    "et = -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf() \n",
    "fig.set_size_inches(12,10)\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.axis([.95, 10.05, 0.3, .85])\n",
    "plt.title('K-NN Accuracy')\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "p1, = ax.plot([None], 'r', label=\"10x10 pixels\")\n",
    "p1, = ax.plot([None], 'y', label=\"16x16 pixels\")\n",
    "p1, = ax.plot([None], 'g', label=\"32x32 pixels\")\n",
    "p1, = ax.plot([None], 'b', label=\"64x64 pixels\")\n",
    "p1, = ax.plot([None], 'ks', label=\"no transformations\")\n",
    "p1, = ax.plot([None], 'ko', label=\"transformations\")\n",
    "p1, = ax.plot([None], 'k--', label=\"no edge detection\")\n",
    "p1, = ax.plot([None], 'k-', label=\"edge detection\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels)\n",
    "for l, s in zip(groups, styles):\n",
    "    xs = [x[0][1] for x in l]\n",
    "    ys = [y[1] for y in l]\n",
    "    plt.plot(xs, ys, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
