{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaf Classification CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#%tensorflow_version 2.x\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys, os, shutil, glob, random, csv, time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IO functions\n",
    "\n",
    "def load_image(file_path):\n",
    "    return cv2.imread(file_path)\n",
    "\n",
    "def create_directory(dirname):\n",
    "    try:\n",
    "        os.mkdir(dirname)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "def extract_names(label_file):\n",
    "    names = list()\n",
    "    with open('label_legend.csv', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        legend = dict(reader)\n",
    "    for img in label_file:\n",
    "        names.append(legend[str(img)])\n",
    "    return names\n",
    "\n",
    "def process_data(source_path, dest_path, desired_size):\n",
    "    create_directory(dest_path)\n",
    "    names = []\n",
    "    legend = dict()\n",
    "    j=0\n",
    "    species_folders = os.listdir(source_path)\n",
    "    for i, folder in enumerate(species_folders):\n",
    "        if folder[0] == '.':\n",
    "            continue\n",
    "        id = str(i).rjust(2, '0')\n",
    "        legend[folder] = id\n",
    "        folder_path = os.listdir(os.path.join(source_path, folder))\n",
    "        num_folders = len(folder_path)\n",
    "        clear_output(wait=True)\n",
    "        print(\"Folder:\", i, \"/99\\r\", flush=True)\n",
    "        for jpgfile in folder_path:\n",
    "            #resize\n",
    "            img = load_image(os.path.join(source_path, folder, jpgfile))\n",
    "            old_size = img.shape[:2]\n",
    "            ratio = float(desired_size)/max(old_size)\n",
    "            new_size = tuple([int(x*ratio) for x in old_size])\n",
    "            img = cv2.resize(img, (new_size[1], new_size[0]))\n",
    "            delta_w = desired_size - new_size[1]\n",
    "            delta_h = desired_size - new_size[0]\n",
    "            top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "            left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "            color = [0, 0, 0]\n",
    "            new_im = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
    "                value=color)\n",
    "            new_im = cv2.cvtColor(new_im, cv2.COLOR_BGR2GRAY)\n",
    "            (thresh, new_im) = cv2.threshold(new_im, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "            #rename\n",
    "            new_name = id + str(j) + '.jpg'\n",
    "            j += 1\n",
    "            fname = os.path.join(dest_path, new_name)\n",
    "            cv2.imwrite(fname, new_im)\n",
    "            #shutil.copy(jpgfile, os.path.join(dest_path, new_name))        \n",
    "    csv_name = 'label_legend.csv'\n",
    "    with open(csv_name, 'w') as csvfile:\n",
    "        for key in legend.keys():\n",
    "            csvfile.write(\"%d,%s\\n\"%(int(legend[key]), key))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: 99 /99\n",
      "Time elapsed:  4.8786652\n"
     ]
    }
   ],
   "source": [
    "#copy dataset into dest_name folder and create a 'label legend'\n",
    "\n",
    "dest_name = 'sixty_four'\n",
    "desired_size = 64\n",
    "\n",
    "#root_path = os.path.join(os.getcwd(), 'drive', 'My Drive', 'datasets')\n",
    "root_path = os.path.join(os.getcwd(), 'datasets')\n",
    "dest_path = os.path.join(root_path, dest_name)\n",
    "process_data(os.path.join(root_path, '100 leaves plant species', 'data'), dest_path, desired_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training labels:  [77, 53, 56, 84, 54, 33, 11, 50, 92, 63]\n",
      "testing labels:  [42, 59, 91, 67, 56, 69, 82, 21, 70, 63]\n",
      "testing names: ['Morus_Nigra', 'Quercus_Coccifera', 'Salix_Intergra', 'Quercus_Ilex', 'Quercus_Castaneifolia', 'Quercus_Infectoria_sub', 'Quercus_Suber', 'Celtis_Koraiensis', 'Quercus_Kewensis', 'Quercus_Dolicholepis']\n"
     ]
    }
   ],
   "source": [
    "#Split processed dataset into training and validation\n",
    "\n",
    "test_perc = .25\n",
    "random_seed = 101\n",
    "data_path = dest_path\n",
    "image_files = os.listdir(dest_path)\n",
    "data = [load_image(os.path.join(data_path, file)) for file in image_files]\n",
    "labels = [int(file[:2]) for file in image_files]\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(data, labels, test_size=test_perc, random_state=random_seed)\n",
    "test_label_name = extract_names(test_labels)\n",
    "print(\"training labels: \", train_labels[:10])\n",
    "print(\"testing labels: \", test_labels[:10])\n",
    "print(\"testing names:\", test_label_name[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess function not being used, any other processing functions can go here \n",
    "def preprocess(img, side=32):\n",
    "    #img = cv2.resize(img, (side,side))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    (thresh, img) = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "    return img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16e302434a8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preview_index = 2\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(train_images[preview_index])\n",
    "#data already mostly processed\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(preprocess(train_images[preview_index]), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leave these loops in case we do transformation or edge functions on images..\n",
    "#for i in range(len(train_images)):\n",
    "#    train_images[i] = preprocess(train_images[i])\n",
    "\n",
    "#for i in range(len(test_images)):\n",
    "#    test_images[i] = preprocess(test_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.int32'>\n",
      "[77 53 56 84 54 33 11 50 92 63 86 27 53 69 19]\n",
      "(1200, 64, 64, 1) (1200,)\n"
     ]
    }
   ],
   "source": [
    "train_images = np.expand_dims(train_images, axis=-1)\n",
    "train_labels = np.array(train_labels)\n",
    "print(type(train_images[0]), type(train_labels[0]))\n",
    "print(train_labels[:15])\n",
    "print(train_images.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONVOLUTIONAL NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "categorical_accuracy() missing 2 required positional arguments: 'y_true' and 'y_pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-cc93550fa098>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m model.compile(optimizer=tf.optimizers.Adam(),\n\u001b[0;32m     20\u001b[0m               \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m               metrics=[tf.metrics.categorical_accuracy()])\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model.tf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: categorical_accuracy() missing 2 required positional arguments: 'y_true' and 'y_pred'"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu, input_shape=train_images.shape[1:]),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    #tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu),\n",
    "    #tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    #tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu),\n",
    "    #tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    #tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    #tf.keras.layers.Dense(units=512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(units=256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(units=100, activation=tf.nn.softmax)\n",
    "]\n",
    "\n",
    "model = tf.keras.Sequential(layers)\n",
    "model.compile(optimizer=tf.optimizers.Adam(),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=15, batch_size=50)\n",
    "model.save_weights(\"model.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = tf.keras.Sequential(layers)\n",
    "eval_model.load_weights(\"model.tf\")\n",
    "eval_predictions = eval_model.predict(np.expand_dims(test_images, axis=-1))\n",
    "cols = 4\n",
    "rows = np.ceil(len(test_images)/cols)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(cols * 4, rows * 4)\n",
    "predicted_labels = np.argmax(eval_predictions, axis=1)\n",
    "predicted_names = extract_names(predicted_labels)\n",
    "predicted_correct = [1 if predicted_labels[i] ==  test_labels[i] else 0 for i in range(len(test_labels))  ]\n",
    "accuracy = np.sum(predicted_correct) / len(test_labels)\n",
    "print(\"Test Accuracy = \", accuracy)\n",
    "for i in range(15):\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.imshow(test_images[i], cmap=\"gray\")\n",
    "    title = predicted_names[i][10:] + \" / \" + test_label_name[i][10:]\n",
    "    plt.title(title)\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
