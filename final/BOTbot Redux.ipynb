{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaf Classification CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#%tensorflow_version 2.x\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys, os, shutil, glob, random, csv, time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data IO / Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IO functions\n",
    "\n",
    "def load_image(file_path):\n",
    "    return cv2.imread(file_path)\n",
    "\n",
    "def create_directory(dirname):\n",
    "    try:\n",
    "        os.mkdir(dirname)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "def extract_names(label_file):\n",
    "    names = list()\n",
    "    with open('label_legend.csv', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        legend = dict(reader)\n",
    "    for img in label_file:\n",
    "        names.append(legend[str(img)])\n",
    "    return names\n",
    "\n",
    "def process_data(source_path, dest_path, desired_size, transform=False, edges=False):\n",
    "    create_directory(dest_path)\n",
    "    names = []\n",
    "    legend = dict()\n",
    "    j=0\n",
    "    species_folders = os.listdir(source_path)\n",
    "    for i, folder in enumerate(species_folders):\n",
    "        if folder[0] == '.':\n",
    "            continue\n",
    "        id = str(i).rjust(2, '0')\n",
    "        legend[folder] = id\n",
    "        folder_path = os.listdir(os.path.join(source_path, folder))\n",
    "        num_folders = len(folder_path)\n",
    "        clear_output(wait=True)\n",
    "        print(\"Folder:\", i, \"/100\", flush=True)\n",
    "        for jpgfile in folder_path:\n",
    "            #resize\n",
    "            img = load_image(os.path.join(source_path, folder, jpgfile))\n",
    "            old_size = img.shape[:2]\n",
    "            ratio = float(desired_size)/max(old_size)\n",
    "            new_size = tuple([int(x*ratio) for x in old_size])\n",
    "            img = cv2.resize(img, (new_size[1], new_size[0]))\n",
    "            delta_w = desired_size - new_size[1]\n",
    "            delta_h = desired_size - new_size[0]\n",
    "            top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "            left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "            color = [0, 0, 0]\n",
    "            new_im = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
    "                value=color)\n",
    "    \n",
    "            #rename\n",
    "            new_name = id + str(j)\n",
    "            j += 1\n",
    "            fname = os.path.join(dest_path, new_name)\n",
    "            if edges:\n",
    "                new_im = cv2.Canny(new_im, 100, 200)\n",
    "            if transform:\n",
    "                # 2x mirror\n",
    "                img_flip_vert = np.flip(new_im, axis=0)\n",
    "                filename = os.path.join(fname + '_vert.jpg')\n",
    "                cv2.imwrite(filename, img_flip_vert)\n",
    "\n",
    "                img_flip_horiz = np.flip(new_im, axis=1)\n",
    "                filename = os.path.join(fname + '_horiz.jpg')\n",
    "                cv2.imwrite(filename, img_flip_horiz)\n",
    "\n",
    "                # rotate 3 times and save\n",
    "                for i in range(1, 4):\n",
    "                    img_flip_vert = cv2.rotate(img_flip_vert, cv2.ROTATE_90_CLOCKWISE)\n",
    "                    filename = os.path.join(fname + '_' + str(i*90) + '_vert.jpg')\n",
    "                    cv2.imwrite(filename, img_flip_vert)\n",
    "\n",
    "                    img_flip_horiz = cv2.rotate(img_flip_horiz, cv2.ROTATE_90_CLOCKWISE)\n",
    "                    filename = os.path.join(fname + '_' + str(i*90) + '_horiz.jpg')\n",
    "                    cv2.imwrite(filename, img_flip_horiz)\n",
    "            cv2.imwrite(os.path.join(fname+'.jpg'), new_im)\n",
    "    csv_name = 'label_legend.csv'\n",
    "    with open(csv_name, 'w') as csvfile:\n",
    "        for key in legend.keys():\n",
    "            csvfile.write(\"%d,%s\\n\"%(int(legend[key]), key))\n",
    "            \n",
    "def blackandwhite(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    (thresh, img) = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "    return img / 255.0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy dataset into dest_name folder and create a 'label legend'\n",
    "\n",
    "dest_name = 'ninety-six'\n",
    "desired_size = 96\n",
    "\n",
    "#root_path = os.path.join(os.getcwd(), 'drive', 'My Drive', 'datasets')\n",
    "root_path = os.path.join(os.getcwd(), 'datasets')\n",
    "dest_path = os.path.join(root_path, dest_name)\n",
    "process_data(os.path.join(root_path, '100 leaves plant species', 'data'), dest_path, desired_size, transform=False, edges=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split processed dataset into training and validation\n",
    "\n",
    "test_perc = .25\n",
    "random_seed = 101\n",
    "data_path = dest_path\n",
    "image_files = os.listdir(dest_path)\n",
    "data = [load_image(os.path.join(data_path, file)) for file in image_files]\n",
    "data = [blackandwhite(img) for img in data]\n",
    "labels = [int(file[:2]) for file in image_files]\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(data, labels, test_size=test_perc, random_state=random_seed)\n",
    "test_label_name = extract_names(test_labels)\n",
    "print(\"training labels: \", train_labels[:10])\n",
    "print(\"testing labels: \", test_labels[:10])\n",
    "print(\"testing names:\", test_label_name[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_index = random.randint(0, len(train_images)-1)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(train_images[preview_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.expand_dims(train_images, axis=-1)\n",
    "test_images = np.expand_dims(test_images, axis=-1)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "print(type(train_images[0]), type(train_labels[0]))\n",
    "print(train_labels[:15])\n",
    "print(train_images.shape, train_labels.shape)\n",
    "print(train_images[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONVOLUTIONAL NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers = [\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu, input_shape=train_images.shape[1:]),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    #tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu),\n",
    "    #tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    #tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu),\n",
    "    #tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    #tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    #tf.keras.layers.Dense(units=512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(units=256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(units=100, activation=tf.nn.softmax)\n",
    "]\n",
    "\n",
    "model = tf.keras.Sequential(layers)\n",
    "model.compile(optimizer=tf.optimizers.Adam(),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=15, batch_size=50)\n",
    "#loss, accuracy = model.Evaluate()\n",
    "model.save_weights(\"model.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = tf.keras.Sequential(layers)\n",
    "eval_model.load_weights(\"model.tf\")\n",
    "eval_predictions = eval_model.predict(np.expand_dims(test_images, axis=-1))\n",
    "cols = 4\n",
    "rows = np.ceil(len(test_images)/cols)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(cols * 4, rows * 4)\n",
    "predicted_labels = np.argmax(eval_predictions, axis=1)\n",
    "predicted_names = extract_names(predicted_labels)\n",
    "predicted_correct = [1 if predicted_labels[i] ==  test_labels[i] else 0 for i in range(len(test_labels))  ]\n",
    "accuracy = np.sum(predicted_correct) / len(test_labels)\n",
    "print(\"Test Accuracy = \", accuracy)\n",
    "for i in range(15):\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.imshow(test_images[i], cmap=\"gray\")\n",
    "    title = predicted_names[i][10:] + \" / \" + test_label_name[i][10:]\n",
    "    plt.title(title)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance between instances x1 and x2\n",
    "def dist(x1, x2):\n",
    "    distance = x1 - x2\n",
    "    return np.linalg.norm(distance)\n",
    "\n",
    "# Predict label for instance x, using k nearest neighbors in training data\n",
    "def classify_knn(train_x, train_y, k, x):\n",
    "    # keep a list of all the distances with the values\n",
    "    distances = []\n",
    "    for i, data in enumerate(train_x):\n",
    "        # caluclate distance between x and data\n",
    "        distance = dist(x, data)\n",
    "        # add distance and label to list\n",
    "        distances.append((distance, train_y[i]))\n",
    "\n",
    "    # sort list of distances\n",
    "    distances.sort()\n",
    "\n",
    "    # tally up the results of the first k items in the sorted list\n",
    "    results = {}\n",
    "    best = (None, 0)\n",
    "    for i in range(k):\n",
    "        distance, label = distances[i]\n",
    "        # increment label by 1 if the label exists, or set to 1 if it doesn't\n",
    "        results[label] = results.get(label, 0) + 1\n",
    "        # keep track of the label with the most \"votes\"\n",
    "        if (results[label] > best[1]):\n",
    "            best = (label, results[label])\n",
    "\n",
    "    return best[0]\n",
    "\n",
    "# Run classifier and compute accuracy\n",
    "def runTest(test_x, test_y, train_x, train_y, k):\n",
    "    num_iters = test_x.shape[0]\n",
    "    correct = 0\n",
    "    i = 1\n",
    "    for (x,y) in zip(test_x, test_y):\n",
    "        clear_output(wait=True)\n",
    "        print('progress: {:.2f}% complete'.format(100* i/num_iters))\n",
    "        i += 1\n",
    "        if classify_knn(train_x, train_y, k, x) == y:\n",
    "            correct += 1\n",
    "    acc = float(correct)/len(test_x)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runTest(test_images, test_labels, train_images, train_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
